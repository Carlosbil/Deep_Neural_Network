{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_HguG1Y0OJ-"
      },
      "source": [
        "# Ejercicio de Feedback 1\n",
        "---\n",
        "\n",
        "## Apartado 1: Ejercicio de Deep Learning\n",
        "Implementar una red neuronal profunda (Deep Neural Network) para la clasificación de\n",
        "imágenes en un conjunto de datos de reconocimiento de objetos. Se espera que los estudiantes\n",
        "diseñen, entrenen y evalúen la red neuronal utilizando técnicas de aprendizaje profundo, como\n",
        "la selección de arquitectura, la optimización de hiperparámetros y la visualización de resultados.\n",
        "Pasos Clave:\n",
        "1. Preparación de datos: Cargar y preprocesar el conjunto de datos.\n",
        "2. Diseño de la arquitectura: Seleccionar una arquitectura de red neuronal profunda\n",
        "adecuada.\n",
        "3. Entrenamiento del modelo: Entrenar la red neuronal utilizando los datos de\n",
        "entrenamiento.\n",
        "4. Evaluación del modelo: Evaluar el rendimiento del modelo en el conjunto de prueba.\n",
        "5. Visualización de resultados: Visualizar ejemplos de imágenes y las predicciones\n",
        "realizadas por la red neuronal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpwLUwsB0OKA",
        "outputId": "ee2bf5b1-d77c-4670-ef7c-11a5c3323108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow was built with CUDA\n",
            "GPUs available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# Lets see if CUDA is available\n",
        "import tensorflow as tf\n",
        "\n",
        "if tf.test.is_built_with_cuda():\n",
        "    print(\"TensorFlow was built with CUDA\")\n",
        "else:\n",
        "    print(\"TensorFlow was not built with CUDA\")\n",
        "\n",
        "print(\"GPUs available: \", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqUf2yLH0OKC"
      },
      "source": [
        "## 1. Preparacion de Datos Cargar y preprocesar el conjunto de datos\n",
        "---\n",
        "\n",
        "El conjunto de datos escogido es el fashion mnist, escogido principalmente para poder descargarlo directamente de la librería Keras, permitiendo al correctos poder usar y ejecutar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oI2O1fL20OKC"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "import os\n",
        "# Descargamos eldataset, generamos un dataframe y lo guardamos como pickle\n",
        "# para no tener que volverlo a descargar la siguiente ejecución\n",
        "# Dado que los labels son numericos, descargaremos también la info\n",
        "# para poder saber que raza significa ese numero\n",
        "train_dataset, info_train = tfds.load('stanford_dogs', split='train', with_info=True, as_supervised=True)\n",
        "test_dataset, info_test = tfds.load('stanford_dogs', split='test', with_info=True, as_supervised=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "u-I-8Qrl8wRm"
      },
      "outputs": [],
      "source": [
        "# Preprocesamiento de las imagenes\n",
        "import tensorflow as tf\n",
        "\n",
        "# Usaremos imagenes de 64x64 para reducir el numero\n",
        "# de neuronas necesario y por tanto mejorar el rendimiento\n",
        "# es cierto, que perderá información y será menos preciso por ello\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "size_image = [100,100]\n",
        "def image_transformation_train(image, label):\n",
        "  # usaremos 2^7 pixeles\n",
        "  image = tf.image.resize(image, size_image)\n",
        "  # es cierto que el color es las razas de perros ayuda a distinguir, pero para\n",
        "  # mejorar el rendimiento demomento usaremos la escala de grises\n",
        "  image = tf.image.rgb_to_grayscale(image)\n",
        "  # normalizar la imagen en 255\n",
        "  image = image/255\n",
        "  image = data_augmentation(image)\n",
        "\n",
        "  return image, label\n",
        "\n",
        "def image_transformation_test(image, label):\n",
        "  # usaremos 2^7 pixeles\n",
        "  image = tf.image.resize(image, size_image)\n",
        "  # es cierto que el color es las razas de perros ayuda a distinguir, pero para\n",
        "  # mejorar el rendimiento demomento usaremos la escala de grises\n",
        "  image = tf.image.rgb_to_grayscale(image)\n",
        "  # normalizar la imagen en 255\n",
        "  image = image/255\n",
        "\n",
        "  return image, label\n",
        "train_dataset = train_dataset.shuffle(1000)\n",
        "\n",
        "train_dataset = train_dataset.map(image_transformation_train)\n",
        "test_dataset = test_dataset.map(image_transformation_test)\n",
        "train_dataset = train_dataset.batch(32)\n",
        "test_dataset = test_dataset.batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD21ye52abK-"
      },
      "source": [
        "##  2.Diseño de la arquitectura\n",
        "---\n",
        "Tras el preprocesado generaremos el modelo al que le podemos indicar el numero de clases con el fin de hacerlo genérico para cualquier dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iN6z1CgaauyL"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.models as models\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def create_model(num_clases, num_dense=120, activ_conv='relu',\n",
        "                 activ_dense='softmax', padding='valid', l2_value=0.01):\n",
        "  return tf.keras.models.Sequential([\n",
        "    ## con el fin de captar mejor las formas de las imagenes, utilizaremos capas\n",
        "    # de convolución, seguidas de Max Pooling para reducir la dimensionalidad\n",
        "    # entre capas.\n",
        "    # primera capa conv-pool\n",
        "    tf.keras.layers.Conv2D(filters=100, kernel_size=(5, 5),\n",
        "                           activation=activ_conv, input_shape=(100, 100, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2), padding=padding),\n",
        "    # segunda capa conv-pool\n",
        "    tf.keras.layers.Conv2D(filters=150, kernel_size=(5, 5),\n",
        "                           activation=activ_conv),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2)),\n",
        "    tf.keras.layers.Conv2D(filters=200, kernel_size=(5, 5),\n",
        "                           activation=activ_conv),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2)),\n",
        "    # usamos flatten para preparar el output de antes para la capa Dense, ya que\n",
        "    # estas esperan una entrada unidimensional.\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(num_dense, activation='relu',\n",
        "                          kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
        "    tf.keras.layers.Dense(num_dense, activation='relu',\n",
        "                          kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
        "    #ultima capa, deberia tener el mismo numero de neuronas que de clases\n",
        "    tf.keras.layers.Dense(num_clases, activation='softmax')\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUsuJz8Fy8ou"
      },
      "source": [
        "## 3. Entrenamiento del modelo\n",
        "---\n",
        "En esta fase generaremos varios modelos con diferentes hiperparámetros puestos\n",
        "con el fin de comparar sus precisiones finales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HUdwe3VzSXb",
        "outputId": "91f2b23f-63c2-43b0-d6cc-7e06f8c68cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creando modelo\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_17 (Conv2D)          (None, 96, 96, 100)       2600      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPooli  (None, 48, 48, 100)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 44, 44, 150)       375150    \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPooli  (None, 22, 22, 150)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 18, 18, 200)       750200    \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPooli  (None, 9, 9, 200)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 16200)             0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               8294912   \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 120)               61560     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9747078 (37.18 MB)\n",
            "Trainable params: 9747078 (37.18 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 5.8040 - accuracy: 0.0068\n",
            "Epoch 1: val_accuracy improved from -inf to 0.00606, saving model to best_model_1.keras\n",
            "375/375 [==============================] - 53s 135ms/step - loss: 5.8040 - accuracy: 0.0068 - val_loss: 5.7778 - val_accuracy: 0.0061 - lr: 0.0100\n",
            "Epoch 2/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 5.7425 - accuracy: 0.0137\n",
            "Epoch 2: val_accuracy improved from 0.00606 to 0.01597, saving model to best_model_1.keras\n",
            "375/375 [==============================] - 52s 137ms/step - loss: 5.7425 - accuracy: 0.0137 - val_loss: 5.6450 - val_accuracy: 0.0160 - lr: 0.0100\n",
            "Epoch 3/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 5.5703 - accuracy: 0.0188\n",
            "Epoch 3: val_accuracy improved from 0.01597 to 0.02145, saving model to best_model_1.keras\n",
            "375/375 [==============================] - 50s 132ms/step - loss: 5.5703 - accuracy: 0.0188 - val_loss: 5.5027 - val_accuracy: 0.0214 - lr: 0.0100\n",
            "Epoch 4/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 5.4617 - accuracy: 0.0237\n",
            "Epoch 4: val_accuracy improved from 0.02145 to 0.02296, saving model to best_model_1.keras\n",
            "375/375 [==============================] - 51s 132ms/step - loss: 5.4617 - accuracy: 0.0237 - val_loss: 5.4318 - val_accuracy: 0.0230 - lr: 0.0100\n",
            "Epoch 5/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 5.3715 - accuracy: 0.0277\n",
            "Epoch 5: val_accuracy improved from 0.02296 to 0.02762, saving model to best_model_1.keras\n",
            "375/375 [==============================] - 49s 130ms/step - loss: 5.3715 - accuracy: 0.0277 - val_loss: 5.3252 - val_accuracy: 0.0276 - lr: 0.0100\n",
            "Epoch 6/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 5.2821 - accuracy: 0.0317\n",
            "Epoch 6: val_accuracy improved from 0.02762 to 0.03065, saving model to best_model_1.keras\n",
            "375/375 [==============================] - 51s 132ms/step - loss: 5.2821 - accuracy: 0.0317 - val_loss: 5.2457 - val_accuracy: 0.0307 - lr: 0.0100\n",
            "Epoch 7/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 5.2060 - accuracy: 0.0357\n",
            "Epoch 7: val_accuracy improved from 0.03065 to 0.03473, saving model to best_model_1.keras\n",
            "375/375 [==============================] - 61s 159ms/step - loss: 5.2060 - accuracy: 0.0357 - val_loss: 5.1715 - val_accuracy: 0.0347 - lr: 0.0100\n",
            "Epoch 8/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 5.1397 - accuracy: 0.0381\n",
            "Epoch 8: val_accuracy improved from 0.03473 to 0.04091, saving model to best_model_1.keras\n",
            "375/375 [==============================] - 64s 170ms/step - loss: 5.1397 - accuracy: 0.0381 - val_loss: 5.1073 - val_accuracy: 0.0409 - lr: 0.0100\n",
            "Epoch 9/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 5.0617 - accuracy: 0.0410\n",
            "Epoch 9: val_accuracy improved from 0.04091 to 0.04359, saving model to best_model_1.keras\n",
            "375/375 [==============================] - 51s 133ms/step - loss: 5.0617 - accuracy: 0.0410 - val_loss: 5.0663 - val_accuracy: 0.0436 - lr: 0.0100\n",
            "Epoch 10/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 5.0052 - accuracy: 0.0483\n",
            "Epoch 10: val_accuracy improved from 0.04359 to 0.04907, saving model to best_model_1.keras\n",
            "375/375 [==============================] - 50s 131ms/step - loss: 5.0052 - accuracy: 0.0483 - val_loss: 5.0229 - val_accuracy: 0.0491 - lr: 0.0100\n",
            "Epoch 11/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 4.9335 - accuracy: 0.0524\n",
            "Epoch 11: val_accuracy did not improve from 0.04907\n",
            "375/375 [==============================] - 56s 147ms/step - loss: 4.9335 - accuracy: 0.0524 - val_loss: 4.9818 - val_accuracy: 0.0486 - lr: 0.0100\n",
            "Epoch 12/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 4.8669 - accuracy: 0.0596\n",
            "Epoch 12: val_accuracy improved from 0.04907 to 0.05431, saving model to best_model_1.keras\n",
            "375/375 [==============================] - 51s 133ms/step - loss: 4.8669 - accuracy: 0.0596 - val_loss: 4.9196 - val_accuracy: 0.0543 - lr: 0.0100\n",
            "Epoch 13/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 4.8076 - accuracy: 0.0608\n",
            "Epoch 13: val_accuracy did not improve from 0.05431\n",
            "375/375 [==============================] - 45s 119ms/step - loss: 4.8076 - accuracy: 0.0608 - val_loss: 4.9185 - val_accuracy: 0.0516 - lr: 0.0100\n",
            "Epoch 14/40\n",
            "375/375 [==============================] - ETA: 0s - loss: 4.7361 - accuracy: 0.0698\n",
            "Epoch 14: val_accuracy improved from 0.05431 to 0.05839, saving model to best_model_1.keras\n",
            "375/375 [==============================] - 61s 161ms/step - loss: 4.7361 - accuracy: 0.0698 - val_loss: 4.9096 - val_accuracy: 0.0584 - lr: 0.0100\n"
          ]
        }
      ],
      "source": [
        "##Generar los modelos\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "#model_1 = create_model(120, num_dense=200, activ_conv='relu',\n",
        "#                 activ_dense='relu', padding='same')\n",
        "file_path = 'best_model_1.keras'\n",
        "#if os.path.isfile(file_path):\n",
        "#  print(\"Cargando modelo\")\n",
        "#  model_1 = tf.keras.models.load_model(file_path)\n",
        "#else:\n",
        "print(\"Creando modelo\")\n",
        "model_1 = create_model(120, num_dense=512, activ_conv='relu',\n",
        "                  activ_dense='softmax', padding='same', l2_value=0.0001)\n",
        "print(model_1.summary())\n",
        "## optimizer, usamos descendiente del gradiente\n",
        "# al aumentar o disminuir momentum dependeremos mas o menos de los gradientes\n",
        "# calculados anteriormente para el proximo salto (actualizacion de pesos)\n",
        "optimizer_a = SGD(learning_rate=0.01, momentum=0.9)\n",
        "\n",
        "# ya use el AdmaW optimizer, pero me funciona peor para este caso que SGD\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=15,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.1,\n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "    min_lr=0.000001\n",
        ")\n",
        "\n",
        "model_1.compile(\n",
        "    optimizer=optimizer_a,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "checkpoint_1 = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max' )\n",
        "\n",
        "## Entrenar los modelos, se guarda el mejor resultado hasta el momento\n",
        "num_epochs = 40\n",
        "batch_size = 32\n",
        "history_1 = model_1.fit(train_dataset, epochs=num_epochs, batch_size=batch_size,\n",
        "                        verbose=1, validation_data=(test_dataset),\n",
        "                        callbacks=[checkpoint_1, early_stopping, reduce_lr])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}